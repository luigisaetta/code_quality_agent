# `agent/graph_agent.py`

## Overview
- Implements a **LangGraph** agent that processes a directory of Python files in a read‑only sandbox.
- The pipeline discovers files, validates file headers, scans for secrets, generates documentation via an LLM, and produces a markdown report.
- Uses a **state‑machine** (`StateGraph`) where each step is a node that mutates an `AgentState` dataclass.
- All file I/O is confined to the supplied `root_dir` (read‑only) and `out_dir` (write‑only) paths.
- Configurable LLM model ID is injected through a `RunnableConfig` (default taken from `agent.config.LLM_MODEL_ID`).

## Public API
| Symbol | Type | Description |
|--------|------|-------------|
| `AgentState` | `@dataclass` | Holds the mutable state passed between graph nodes (request, paths, file list, findings, docs, summary). |
| `build_graph()` | `() -> StateGraph` | Constructs and returns the compiled LangGraph pipeline. |
| `run_agent(graph, *, root_dir: str, out_dir: str, request: str) -> Awaitable[AgentState]` | Async function | Executes the graph with the given directories and user request, returning the final `AgentState`. |

## Key Behaviors and Edge Cases
- **Read‑only sandbox** (`ReadOnlySandboxFS`) guarantees that the agent cannot modify source files under `root_dir`.
- **Header validation** (`check_header`) logs an issue per file when the header does not meet the expected format; the result is stored in `state.header_issues`.
- **Secret scanning** (`scan_for_secrets`) aggregates any findings; empty results are omitted from the final dict.
- **Documentation generation** is asynchronous and uses the LLM returned by `get_llm`. It passes the original request string to `generate_doc_for_file`, enabling request‑aware docs.
- **Final report** is generated by formatting `REPORT_PROMPT` with runtime data, calling the LLM, and writing a `report_YYYY‑MM‑DD.md` file to `out_dir`.
- **Config handling**: `model_id` is extracted from the `RunnableConfig` via `get_config_value`. If missing, the default LLM model from `agent.config.LLM_MODEL_ID` is used.
- **Edge cases**:
  - If `root_dir` contains no Python files, the pipeline still runs but produces empty collections and a minimal report.
  - Errors raised inside any node (e.g., I/O errors, LLM failures) will abort the graph unless caught upstream; the current implementation does not include explicit error handling.
  - The `out_dir` is resolved with `expanduser().resolve()`, so relative paths are safely normalized.

## Inputs / Outputs / Side Effects
| Component | Input | Output | Side Effects |
|-----------|-------|--------|--------------|
| `run_agent` | `graph`, `root_dir`, `out_dir`, `request` | Final `AgentState` | Writes generated docs and a markdown report to `out_dir`. |
| `node_discover_files` | `AgentState.root_dir` | `state.file_list` | Reads directory structure via sandbox FS. |
| `node_check_headers` | `state.file_list` | `state.header_issues` | Logs per‑file header checks. |
| `node_scan_secrets` | `state.file_list` | `state.secrets` | Logs per‑file secret scans. |
| `node_generate_docs` | `state.file_list`, `state.request`, LLM | `state.docs` (mapping relpath → generated doc path) | Writes documentation files under `out_dir`. |
| `node_finalize` | All accumulated state | `state.summary` + markdown report file | Writes `report_YYYY‑MM‑DD.md` to `out_dir`. |

## Usage Examples
```python
import asyncio
from agent.graph_agent import build_graph, run_agent

async def main():
    # Build the reusable graph once
    graph = build_graph()

    # Run the agent on a project directory
    final_state = await run_agent(
        graph,
        root_dir="~/my_project/src",
        out_dir="~/my_project/reports",
        request="Create API documentation for the public modules."
    )

    # Quick inspection of the summary
    print(final_state.summary)

    # Access generated documentation paths
    for rel_path, doc_path in final_state.docs.items():
        print(f"{rel_path} → {doc_path}")

asyncio.run(main())
```

## Risks / TODOs
- **Secret exposure**: `node_scan_secrets` collects potential secrets from source files and stores them in `state.secrets`. While the agent itself does not persist these findings beyond the final report, downstream handling (e.g., logging, external storage) must ensure they are not inadvertently leaked.
- **Error handling**: No try/except blocks around file I/O or LLM calls; a single failure aborts the whole pipeline. Consider adding robust error recovery and reporting.
- **Config validation**: `get_config_value` silently falls back to defaults; malformed configs could lead to unexpected LLM selection. Add validation or explicit warnings.
- **Performance**: The pipeline processes files sequentially. For large codebases, parallelizing header checks, secret scans, or doc generation could improve throughput.
- **Testing**: Unit tests for each node (especially the async ones) are not shown; ensure mocks for `ReadOnlySandboxFS`, LLM, and secret scanner are in place.
